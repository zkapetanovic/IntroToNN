{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np\n",
    "import timeit\n",
    "import load_cifar as data\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Hyperparameter</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10;\n",
    "batch_size = 128\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Placeholder</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Define placeholders\n",
    "x = tf.placeholder(tf.float32, shape=(None, 32, 32, 3), name='input')\n",
    "y = tf.placeholder(tf.float32, shape=(None, 10), name='output')\n",
    "d = tf.placeholder(tf.float32, name=\"droput_rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>LeNet-5</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lenet5(x):\n",
    "    \n",
    "    ###### Convolution layer 6 @ 28x28 ######\n",
    "\n",
    "    W1 = tf.Variable(tf.truncated_normal(shape=(5,5,3,6), mean = 0, stddev = 0.1))\n",
    "    b1 = tf.Variable(tf.zeros(6))\n",
    "\n",
    "    l1 = tf.nn.conv2d(x, W1, strides=[1,1,1,1], padding='VALID') + b1\n",
    "    l1 = tf.nn.relu(l1)\n",
    "    l1 = tf.nn.max_pool(l1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID')\n",
    "\n",
    "    ###### Convolution layer 16 @ 10x10 ######\n",
    "\n",
    "    W2 = tf.Variable(tf.truncated_normal(shape=(5,5,6,16), mean = 0, stddev = 0.1))\n",
    "    b1 = tf.Variable(tf.zeros(16))\n",
    "\n",
    "    l2 = tf.nn.conv2d(l1, W2, strides=[1,1,1,1], padding='VALID')\n",
    "    l2 = tf.nn.relu(l2)\n",
    "    l2 = tf.nn.max_pool(l2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='VALID')\n",
    "\n",
    "    ###### Fully connected (400 --> 120) ######\n",
    "    flat = tf.contrib.layers.flatten(l2)\n",
    "\n",
    "    W3 = tf.Variable(tf.truncated_normal(shape=(400,120), mean = 0, stddev = 0.1))\n",
    "    b3 = tf.Variable(tf.zeros(120))\n",
    "\n",
    "    l3 = tf.matmul(flat, W3) + b3\n",
    "    l3 = tf.nn.relu(l3)\n",
    "\n",
    "    ###### Fully connected (120 --> 84) ######\n",
    "    W4 = tf.Variable(tf.truncated_normal(shape=(120,84), mean = 0, stddev = 0.1))\n",
    "    b4 = tf.Variable(tf.zeros(84))\n",
    "\n",
    "    l4 = tf.matmul(l3, W4) + b4\n",
    "    l4 = tf.nn.relu(l4)\n",
    "\n",
    "    ###### Fully connected (84 --> 10) ######\n",
    "    W5 = tf.Variable(tf.truncated_normal(shape=(84,10), mean = 0, stddev = 0.1))\n",
    "    b5 = tf.Variable(tf.zeros(10))\n",
    "    \n",
    "    logits = tf.matmul(l4, W5) + b5\n",
    "    \n",
    "    return logits \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Cost and Optimization</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = lenet5(x)\n",
    "\n",
    "#define loss\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,labels=y),name='loss')\n",
    "\n",
    "#define optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=lr)\n",
    "train_op = optimizer.minimize(cost)\n",
    "\n",
    "corr_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "acc = tf.reduce_mean(tf.cast(corr_pred, tf.float32))\n",
    "\n",
    "def get_stats(session, cost, accuracy, b_feat, b_labels, v_feat, v_labels):\n",
    "    loss = sess.run(cost,\n",
    "                   feed_dict={\n",
    "                       x: b_feat,\n",
    "                       y: b_labels, \n",
    "                   })\n",
    "    \n",
    "    acc = sess.run(accuracy, \n",
    "                  feed_dict={\n",
    "                      x: v_feat,\n",
    "                      y: v_labels,\n",
    "                  })\n",
    "\n",
    "    print('Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Training, validation and testing</h1>\n",
    "<h2>Train your model only 10 epochs.</h2>\n",
    "<h2>1.Print out validation accuracy after each training epoch</h2>\n",
    "<h2>2.Print out training time for each training epoch</h2>\n",
    "<h2>3.Print out testing accuracy</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.3077 Validation Accuracy: 0.129400\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss:     2.2784 Validation Accuracy: 0.157400\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss:     2.2202 Validation Accuracy: 0.174800\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss:     2.1867 Validation Accuracy: 0.191600\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss:     2.0725 Validation Accuracy: 0.235000\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     2.2587 Validation Accuracy: 0.247000\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss:     2.0552 Validation Accuracy: 0.259600\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss:     1.8299 Validation Accuracy: 0.254200\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss:     1.9488 Validation Accuracy: 0.280200\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss:     1.9832 Validation Accuracy: 0.295000\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     2.2300 Validation Accuracy: 0.300200\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss:     2.0040 Validation Accuracy: 0.302400\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss:     1.6931 Validation Accuracy: 0.302200\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss:     1.8320 Validation Accuracy: 0.319400\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss:     1.8986 Validation Accuracy: 0.341200\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     2.1531 Validation Accuracy: 0.339400\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss:     1.9499 Validation Accuracy: 0.339600\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss:     1.5914 Validation Accuracy: 0.322400\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss:     1.7204 Validation Accuracy: 0.353600\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss:     1.8155 Validation Accuracy: 0.374000\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     2.0533 Validation Accuracy: 0.349200\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss:     1.9139 Validation Accuracy: 0.356000\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss:     1.5218 Validation Accuracy: 0.342400\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss:     1.6411 Validation Accuracy: 0.382600\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss:     1.7490 Validation Accuracy: 0.394200\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     1.9272 Validation Accuracy: 0.374800\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss:     1.8701 Validation Accuracy: 0.383600\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss:     1.4089 Validation Accuracy: 0.368200\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss:     1.5857 Validation Accuracy: 0.407000\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss:     1.6849 Validation Accuracy: 0.409200\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     1.8909 Validation Accuracy: 0.374800\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss:     1.8100 Validation Accuracy: 0.407200\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss:     1.2903 Validation Accuracy: 0.399000\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss:     1.5422 Validation Accuracy: 0.427000\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss:     1.6093 Validation Accuracy: 0.418000\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     1.8427 Validation Accuracy: 0.396200\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss:     1.7739 Validation Accuracy: 0.424000\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss:     1.2336 Validation Accuracy: 0.417600\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss:     1.5117 Validation Accuracy: 0.435200\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss:     1.5576 Validation Accuracy: 0.426800\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     1.7927 Validation Accuracy: 0.411600\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss:     1.7356 Validation Accuracy: 0.434200\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss:     1.1879 Validation Accuracy: 0.431000\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss:     1.4846 Validation Accuracy: 0.437400\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss:     1.4952 Validation Accuracy: 0.444400\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     1.7382 Validation Accuracy: 0.429800\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss:     1.7002 Validation Accuracy: 0.441200\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss:     1.1571 Validation Accuracy: 0.443600\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss:     1.4515 Validation Accuracy: 0.440200\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss:     1.4531 Validation Accuracy: 0.448800\n"
     ]
    }
   ],
   "source": [
    "#Initialize the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "v_feat, v_labels = pickle.load(open('preprocessed_validation.p', mode='rb'))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches+1):\n",
    "            for batch_x, batch_y in data.load_preprocessed_training_batch(batch_i, batch_size):\n",
    "                sess.run(train_op, feed_dict={x:batch_x, y:batch_y})\n",
    "\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            get_stats(sess, cost, acc, batch_x, batch_y, v_feat, v_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
