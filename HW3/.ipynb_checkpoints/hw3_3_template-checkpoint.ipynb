{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data\n",
    "In the <b>HW3_template</b> folder you will find `TSLA.csv`, `GOOGL.csv` and `DJI.csv` files. Use Pandas (You have used it in HW1) to retrieve the dataset. Use only <b>Open</b> price as your input. (You will train three models for three different stocks, don't mix these data together!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-06-29</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>25.00</td>\n",
       "      <td>17.540001</td>\n",
       "      <td>23.889999</td>\n",
       "      <td>23.889999</td>\n",
       "      <td>18766300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-06-30</td>\n",
       "      <td>25.790001</td>\n",
       "      <td>30.42</td>\n",
       "      <td>23.299999</td>\n",
       "      <td>23.830000</td>\n",
       "      <td>23.830000</td>\n",
       "      <td>17187100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-07-01</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.92</td>\n",
       "      <td>20.270000</td>\n",
       "      <td>21.959999</td>\n",
       "      <td>21.959999</td>\n",
       "      <td>8218800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-07-02</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.10</td>\n",
       "      <td>18.709999</td>\n",
       "      <td>19.200001</td>\n",
       "      <td>19.200001</td>\n",
       "      <td>5139800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-07-06</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.00</td>\n",
       "      <td>15.830000</td>\n",
       "      <td>16.110001</td>\n",
       "      <td>16.110001</td>\n",
       "      <td>6866900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open   High        Low      Close  Adj Close    Volume\n",
       "0  2010-06-29  19.000000  25.00  17.540001  23.889999  23.889999  18766300\n",
       "1  2010-06-30  25.790001  30.42  23.299999  23.830000  23.830000  17187100\n",
       "2  2010-07-01  25.000000  25.92  20.270000  21.959999  21.959999   8218800\n",
       "3  2010-07-02  23.000000  23.10  18.709999  19.200001  19.200001   5139800\n",
       "4  2010-07-06  20.000000  20.00  15.830000  16.110001  16.110001   6866900"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('TSLA.csv')\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset['Open'].values\n",
    "data = data.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize your data\n",
    "You could use `MinMaxScaler` in `sklearn.preprocessing` to normalize the data between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2227\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "data_norm = scaler.fit_transform(data)\n",
    "print(len(data_norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Define Hyperparameters #####\n",
    "epochs = 100\n",
    "batch_size = 10\n",
    "learning_rate = 0.01\n",
    "num_layers = 1\n",
    "h_layer_size = 512\n",
    "dropout = 0.2\n",
    "num_seq = 10\n",
    "num_units  = 200\n",
    "input_size = 1\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split training, validation and testing data\n",
    "<p style=\"font-size:20px\">Since you will impelement a many-to-one Recurrent Neural Network model, every input data will have shape [batch_size, num_seq, input_size] and output data will have shape [batch_size, input_size] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2217"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def window(data, num_seq):\n",
    "    data_ = []\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    for i in range(len(data) - num_seq):\n",
    "        data_.append(data[i:i+num_seq])\n",
    "\n",
    "    return data_\n",
    "\n",
    "data_n = window(data_norm, num_seq)\n",
    "len(data_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n"
     ]
    }
   ],
   "source": [
    "data_n = np.array(data_n)\n",
    "X_train = data_n[:1000,:-1,:]\n",
    "Y_train = data_n[:1000,-1,:]\n",
    "\n",
    "X_test = data_n[1000:2000,:-1,:]\n",
    "Y_test = data_n[1000:2000,-1,:]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.placeholder(tf.float32, [None, num_seq-1, input_size])\n",
    "outputs = tf.placeholder(tf.float32, [None, input_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [tf.contrib.rnn.BasicLSTMCell(num_units=num_units, activation=tf.nn.relu) for layer in range(num_layers)]\n",
    "\n",
    "multi_layer = tf.contrib.rnn.MultiRNNCell(layers)\n",
    "\n",
    "lstm_out, states = tf.nn.dynamic_rnn(multi_layer, inputs, dtype=tf.float32)\n",
    "\n",
    "stacked_outputs = tf.layers.dense(tf.reshape(lstm_out, [-1, num_units]), input_size)\n",
    "\n",
    "out = tf.reshape(stacked_outputs, [-1, num_seq-1, input_size])\n",
    "out = out[:,num_seq-2,:]\n",
    "\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(out-outputs)) #MSE\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "0.00 epochs: MSE train/valid = 0.012431/0.074390\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "2.00 epochs: MSE train/valid = 0.005741/0.043660\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "4.00 epochs: MSE train/valid = 0.032384/0.241580\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "6.00 epochs: MSE train/valid = 0.031948/0.257140\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "8.00 epochs: MSE train/valid = 0.027414/0.234934\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "10.00 epochs: MSE train/valid = 0.020937/0.188158\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "12.00 epochs: MSE train/valid = 0.013187/0.111692\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "14.00 epochs: MSE train/valid = 0.009388/0.024143\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "16.00 epochs: MSE train/valid = 0.007514/0.001101\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "18.00 epochs: MSE train/valid = 0.001985/0.002253\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "20.00 epochs: MSE train/valid = 0.001878/0.003696\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "22.00 epochs: MSE train/valid = 0.001067/0.039898\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "24.00 epochs: MSE train/valid = 0.002045/0.092284\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "26.00 epochs: MSE train/valid = 0.001877/0.023858\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "28.00 epochs: MSE train/valid = 0.001550/0.017581\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "30.00 epochs: MSE train/valid = 0.001078/0.033444\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "32.00 epochs: MSE train/valid = 0.000896/0.022376\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "34.00 epochs: MSE train/valid = 0.000641/0.004437\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "36.00 epochs: MSE train/valid = 0.000763/0.001300\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "38.00 epochs: MSE train/valid = 0.000646/0.001082\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "40.00 epochs: MSE train/valid = 0.000564/0.001808\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "42.00 epochs: MSE train/valid = 0.000542/0.002371\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "44.00 epochs: MSE train/valid = 0.000364/0.001269\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "46.00 epochs: MSE train/valid = 0.000315/0.000815\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "48.00 epochs: MSE train/valid = 0.000302/0.000844\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "50.00 epochs: MSE train/valid = 0.000225/0.000806\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "52.00 epochs: MSE train/valid = 0.000246/0.000897\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n",
      "(1000, 9, 1)\n",
      "(1000, 1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-638cce497756>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(epochs):\n",
    "        sess.run(training_op, feed_dict={inputs:X_train, outputs:Y_train})\n",
    "    \n",
    "        if epoch % 2 == 0:\n",
    "            acc_train = loss.eval(feed_dict={inputs: X_train, outputs: Y_train}) \n",
    "            acc_valid = loss.eval(feed_dict={inputs:X_test, outputs: Y_test}) \n",
    "            \n",
    "            print('%.2f epochs: MSE train/valid = %.6f/%.6f'%(epoch, acc_train, acc_valid))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Model\n",
    "\n",
    "<p style=\"font-size:15px\">I'm going to use an LSTM model. I made this choice because I think I want to use this for my final project so this is good practice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Define Weights and Bias ########\n",
    "\n",
    "W1 = tf.Variable(tf.truncated_normal([input_size, h_layer_size], stddev=0.05, name='W1'))\n",
    "W2 = tf.Variable(tf.truncated_normal([h_layer_size, h_layer_size], stddev=0.05, name='W2'))\n",
    "b1 = tf.Variable(tf.zeros([h_layer_size]), name='b1')\n",
    "\n",
    "W3 = tf.Variable(tf.truncated_normal([input_size, h_layer_size], stddev=0.05, name='W3'))\n",
    "W4 = tf.Variable(tf.truncated_normal([h_layer_size, h_layer_size], stddev=0.05, name='W4'))\n",
    "b2 = tf.Variable(tf.zeros([h_layer_size]), name='b2')\n",
    "\n",
    "W5 = tf.Variable(tf.truncated_normal([input_size, h_layer_size], stddev=0.05, name='W5'))\n",
    "W6 = tf.Variable(tf.truncated_normal([h_layer_size, h_layer_size], stddev=0.05, name='W6'))\n",
    "b3 = tf.Variable(tf.zeros([h_layer_size]), name='b3')\n",
    "\n",
    "W7 = tf.Variable(tf.truncated_normal([input_size, h_layer_size], stddev=0.05, name='W7'))\n",
    "W8 = tf.Variable(tf.truncated_normal([h_layer_size, h_layer_size], stddev=0.05, name='W8'))\n",
    "b4 = tf.Variable(tf.zeros([h_layer_size]), name='b4')\n",
    "\n",
    "Wout = tf.Variable(tf.truncated_normal([h_layer_size, input_size], stddev=0.05, name=\"Wout\"))\n",
    "bout = tf.Variable(tf.zeros([1]), name=\"bout\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:15px\">\n",
    "I followed this page: https://colah.github.io/posts/2015-08-Understanding-LSTMs/ to figure out how to create the LSTM model.\n",
    "\n",
    "1) A sigmoid layer \"forget gate layer\". Outputs a value betwen 0 and 1 for each cell state to decided what to keep and what to \"forget\".\n",
    "\n",
    "2) Another sigmoid layer \"input gate layer\" to decide which values to update and a tanh layer to create new cell states.\n",
    "    \n",
    "3) Last step is the \"output layer\" A sigmoid layer to decide what parts of the cell state to ouput. Then a tanh layer and multiply it by the output of the sigmoid. \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model(inputs, outputs, cell_state):\n",
    "    input_ = tf.sigmoid(tf.matmul(inputs, W1) + tf.matmul(outputs, W2) + b1)\n",
    "    forget = tf.sigmoid(tf.matmul(inputs, W3) + tf.matmul(outputs, W4) + b2)\n",
    "    output = tf.sigmoid(tf.matmul(inputs, W5) + tf.matmul(outputs, W6) + b3)\n",
    "    mem = tf.tanh(tf.matmul(inputs, W7) + tf.matmul(outputs, W8) + b4)\n",
    "    \n",
    "    cell_state = cell_state*forget + input_*mem\n",
    "    out = output*tf.tanh(cell_state)\n",
    "    \n",
    "    return out, cell_state\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
