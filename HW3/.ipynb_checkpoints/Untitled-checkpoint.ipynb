{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import os\n",
    "import collections\n",
    "from six.moves import cPickle\n",
    "import numpy as np\n",
    "import io\n",
    "import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a class object that should have the following functions:\n",
    "\n",
    "1) object initialization:\n",
    "This function should be able to take arguments of data directory, batch size and sequence length.\n",
    "The initialization should be able to process data, load preprocessed data and create training and \n",
    "validation mini batches.\n",
    "\n",
    "2)helper function to preprocess the text data:\n",
    "This function should be able to do:\n",
    "    a)read the txt input data using encoding='utf-8'\n",
    "    b)\n",
    "        b1)create self.char that is a tuple contains all unique character appeared in the txt input.\n",
    "        b2)create self.vocab_size that is the number of unique character appeared in the txt input.\n",
    "        b3)create self.vocab that is a dictionary that the key is every unique character and its value is a unique integer label.\n",
    "    c)split training and validation data.\n",
    "    d)save your self.char as pickle (pkl) file that you may use later.\n",
    "    d)map all characters of training and validation data to their integer label and save as 'npy' files respectively.\n",
    "\n",
    "3)helper function to load preprocessed data\n",
    "\n",
    "4)helper functions to create training and validation mini batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load Data ####\n",
    "filename='shakespeare.txt'\n",
    "batch_size = 10\n",
    "seq_len = 40\n",
    "window = 3\n",
    "\n",
    "text = io.open(filename, encoding='utf-8').read().lower()\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "char_to_int = dict((c,i) for i, c in enumerate(chars))\n",
    "\n",
    "num_chars = len(text)\n",
    "num_vocab = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Create training data ####\n",
    "def gen_data_set(text, batch_size, seq_len, window):\n",
    "\n",
    "    X, Y = [], []\n",
    "\n",
    "    for i in range(0, len(text)-seq_len, window):\n",
    "        X.append(text[i: i + seq_len])\n",
    "        Y.append(text[i + seq_len])\n",
    "        \n",
    "    print('number of training examples:', len(X))\n",
    "    \n",
    "    return X, Y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples: 1524433\n"
     ]
    }
   ],
   "source": [
    "X, Y = gen_data_set(text, batch_size, seq_len, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['st citizen:\\nbefore we proceed any furthe', 'citizen:\\nbefore we proceed any further, ', 'izen:\\nbefore we proceed any further, hea', 'n:\\nbefore we proceed any further, hear m', 'before we proceed any further, hear me s', 'ore we proceed any further, hear me spea', ' we proceed any further, hear me speak.\\n', ' proceed any further, hear me speak.\\n\\nal', 'oceed any further, hear me speak.\\n\\nall:\\n']\n"
     ]
    }
   ],
   "source": [
    "print(X[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile text_utils.py\n",
    "import codecs\n",
    "import os\n",
    "import collections\n",
    "from six.moves import cPickle\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "Implement a class object that should have the following functions:\n",
    "\n",
    "1) object initialization:\n",
    "This function should be able to take arguments of data directory, batch size and sequence length.\n",
    "The initialization should be able to process data, load preprocessed data and create training and \n",
    "validation mini batches.\n",
    "\n",
    "2)helper function to preprocess the text data:\n",
    "This function should be able to do:\n",
    "    a)read the txt input data using encoding='utf-8'\n",
    "    b)\n",
    "        b1)create self.char that is a tuple contains all unique character appeared in the txt input.\n",
    "        b2)create self.vocab_size that is the number of unique character appeared in the txt input.\n",
    "        b3)create self.vocab that is a dictionary that the key is every unique character and its value is a unique integer label.\n",
    "    c)split training and validation data.\n",
    "    d)save your self.char as pickle (pkl) file that you may use later.\n",
    "    d)map all characters of training and validation data to their integer label and save as 'npy' files respectively.\n",
    "\n",
    "3)helper function to load preprocessed data\n",
    "\n",
    "4)helper functions to create training and validation mini batches\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "class TextLoader():\n",
    "    def __init__(self, filename=None, batch_size=None, seq_len=None):\n",
    "        \n",
    "        if filename != None:\n",
    "            self.text = self.load_file(filename)\n",
    "        \n",
    "        self.chars = self.get_characters(text)\n",
    "        self.char_to_int = self.char_2_int(self.chars)\n",
    "        self.num_chars = len(self.text)\n",
    "        self.num_vocab = len(self.chars)\n",
    "        X, Y = self.gen_data_set(self.text, seq_len, self.num_chars, self.char_to_int, self.chars)\n",
    "        \n",
    "        X_train, Y_train = self.process_data_set(X, Y, seq_len, self.num_vocab)\n",
    "    def load_file(self, filename):\n",
    "        text = io.open(filename, encoding='utf-8').read().lower()\n",
    "        return text\n",
    "    \n",
    "    def get_characters(self, text):\n",
    "        chars = sorted(list(set(text)))\n",
    "        return chars\n",
    "    \n",
    "    def char_2_int(slef, chars):\n",
    "        char_to_int = dict((c,i) for i, c in enumerate(chars))\n",
    "        return char_to_int\n",
    "    \n",
    "    def gen_data_set(self, text, seq_len, num_chars, char_to_int, char):\n",
    "\n",
    "        X, Y = [], []\n",
    "\n",
    "        for i in range(0, num_chars-seq_len, 1):\n",
    "            in_ = text[i: i + seq_len]\n",
    "            out_ = text[i + seq_len]\n",
    "            X.append([char_to_int[c] for c in in_])\n",
    "            Y.append(char_to_int[out_])\n",
    "\n",
    "        print('Number of Training Examples:', len(X))\n",
    "\n",
    "        return X, Y\n",
    "    \n",
    "    def process_data_set(self, X, Y, seq_len, num_vocab):\n",
    "        X_data = np.reshape(X, (len(X), seq_len,1))\n",
    "        X_data = X_data/float(num_vocab)\n",
    "        \n",
    "        #Y_data = np_utils.to_categorical(Y)\n",
    "        \n",
    "        return X_data, Y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Examples: 4573298\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.TextLoader at 0x11f672358>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = TextLoader('shakespeare.txt', batch_size, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
